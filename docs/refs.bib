@article{Bessler01061984,
    title = {A Note on Tests of {{Granger}} Causality},
    author = {Bessler, D. A. and Kling, J. L.},
    year = {1984},
    journal = {Applied Economics},
    volume = {16},
    number = {3},
    pages = {335--342},
    publisher = {Routledge},
    doi = {10.1080/00036848400000041}
}

@book{dieboldElementsForecasting1997,
    title = {Elements of {{Forecasting}}},
    author = {Diebold, Francis X.},
    year = {1997},
    month = sep,
    edition = {4st edition},
    publisher = {Cengage Learning},
    address = {Cincinnati, Ohio},
    abstract = {Elements of Forecasting is a concise, modern survey of business and economics forecasting. Written by one of the world's leading experts on forecasting, the text focuses on the core techniques with the widest applicability. It is applications-oriented and illustrates all methods with detailed, real-world application.},
    isbn = {978-0-538-86244-8},
    langid = {english}
}

@article{grangerInvestigatingCausalRelations1969,
    title = {Investigating {{Causal Relations}} by {{Econometric Models}} and {{Cross-spectral Methods}}},
    author = {Granger, C. W. J.},
    year = {1969},
    month = aug,
    journal = {Econometrica},
    volume = {37},
    number = {3},
    pages = {424},
    issn = {00129682},
    doi = {10.2307/1912791},
    urldate = {2024-03-15}
}

@article{zaninAssessingGrangerCausality2021,
    title = {Assessing {{Granger Causality}} on {{Irregular Missing}} and {{Extreme Data}}},
    author = {Zanin, Massimiliano},
    year = {2021},
    journal = {IEEE Access},
    volume = {9},
    pages = {75362--75374},
    issn = {2169-3536},
    doi = {10.1109/ACCESS.2021.3082014},
    urldate = {2024-03-15},
    abstract = {The Granger test is one of the best known techniques to detect causality relationships among time series, and has been used uncountable times in science and engineering. The quality of its results strongly depends on the quality of the underlying data, and different approaches have been proposed to reduce the impact of, for instance, observational noise or irregular sampling. Less attention has nevertheless been devoted to situations in which the analysed time series are irregularly polluted with missing and extreme values. In this contribution I tackle this problem by comparing four different data pre-processing strategies and evaluating their performance with synthetic time series, both in dyadic tests and functional network contexts. I further apply these strategies to a real-world problem, involving inferring the structure behind the propagation of delays in an air transport system. Finally, some guidelines are provided on when and how these strategies ought to be used.},
    keywords = {Couplings,Dynamics,Europe,functional networks,Granger causality,missing data,Pollution measurement,Predictive models,Standards,Time series analysis}
}

@article{rajapakseLearningEffectiveBrain2007,
    title = {Learning Effective Brain Connectivity with Dynamic {{Bayesian}} Networks},
    author = {Rajapakse, Jagath C. and Zhou, Juan},
    year = {2007},
    month = sep,
    journal = {NeuroImage},
    volume = {37},
    number = {3},
    pages = {749--760},
    issn = {1053-8119},
    doi = {10.1016/j.neuroimage.2007.06.003},
    urldate = {2025-06-06},
    abstract = {We propose to use dynamic Bayesian networks (DBN) to learn the structure of effective brain connectivity from functional MRI data in an exploratory manner. In our previous work, we used Bayesian networks (BN) to learn the functional structure of the brain (Zheng, X., Rajapakse, J.C., 2006. Learning functional structure from fMR images. NeuroImage 31 (4), 1601--1613). However, BN provides a single snapshot of effective connectivity of the entire experiment and therefore is unable to accurately capture the temporal characteristics of connectivity. Dynamic Bayesian networks (DBN) use a Markov chain to model fMRI time-series and thereby determine temporal relationships of interactions among brain regions. Experiments on synthetic fMRI data demonstrate that the performance of DBN is comparable to Granger causality mapping (GCM) in determining the structure of linearly connected networks. Dynamic Bayesian networks render more accurate and informative brain connectivity than earlier methods as connectivity is described in complete statistical sense and temporal characteristics of time-series are explicitly taken into account. The functional structures inferred on two real fMRI datasets are consistent with the previous literature and more accurate than those discovered by BN. Furthermore, we study the effects of hemodynamic noise, scanner noise, inter-scan interval, and the variability of hemodynamic parameters on the derived connectivity.},
    keywords = {Bayesian networks,Causal effects,Dynamic Bayesian networks,Effective connectivity,Functional MRI,Hemodynamic response function,Markov chain Monte Carlo methods,Markov chains}
}

@article{roebroeckMappingDirectedInfluence2005,
    title = {Mapping Directed Influence over the Brain Using {{Granger}} Causality and {{fMRI}}},
    author = {Roebroeck, Alard and Formisano, Elia and Goebel, Rainer},
    year = {2005},
    month = mar,
    journal = {NeuroImage},
    volume = {25},
    number = {1},
    pages = {230--242},
    issn = {1053-8119},
    doi = {10.1016/j.neuroimage.2004.11.017},
    urldate = {2025-06-06},
    abstract = {We propose Granger causality mapping (GCM) as an approach to explore directed influences between neuronal populations (effective connectivity) in fMRI data. The method does not rely on a priori specification of a model that contains pre-selected regions and connections between them. This distinguishes it from other fMRI effective connectivity approaches that aim at testing or contrasting specific hypotheses about neuronal interactions. Instead, GCM relies on the concept of Granger causality to define the existence and direction of influence from information in the data. Temporal precedence information is exploited to compute Granger causality maps that identify voxels that are sources or targets of directed influence for any selected region-of-interest. We investigated the method by simulations and by application to fMRI data of a complex visuomotor task. The presented exploratory approach of mapping influences between a region of interest and the rest of the brain can form a useful complement to existing models of effective connectivity.},
    keywords = {Autoregressive models,Effective connectivity,fMRI,Granger causality}
}

@article{brandesVariantsShortestpathBetweenness2008,
    title = {On Variants of Shortest-Path Betweenness Centrality and Their Generic Computation},
    author = {Brandes, Ulrik},
    year = {2008},
    month = may,
    journal = {Social Networks},
    volume = {30},
    number = {2},
    pages = {136--145},
    issn = {0378-8733},
    doi = {10.1016/j.socnet.2007.11.001},
    urldate = {2022-03-23},
    abstract = {Betweenness centrality based on shortest paths is a standard measure of control utilized in numerous studies and implemented in all relevant software tools for network analysis. In this paper, a number of variants are reviewed, placed into context, and shown to be computable with simple variants of the algorithm commonly used for the standard case.},
    langid = {english},
    keywords = {Algorithms,Betweenness centrality,Load centrality,Valued networks}
}

@article{latoraEfficientBehaviorSmallWorld2001,
    title = {Efficient {{Behavior}} of {{Small-World Networks}}},
    author = {Latora, Vito and Marchiori, Massimo},
    year = {2001},
    month = oct,
    journal = {Physical Review Letters},
    volume = {87},
    number = {19},
    pages = {198701},
    publisher = {American Physical Society},
    doi = {10.1103/PhysRevLett.87.198701},
    urldate = {2023-02-13},
    abstract = {We introduce the concept of efficiency of a network as a measure of how efficiently it exchanges information. By using this simple measure, small-world networks are seen as systems that are both globally and locally efficient. This gives a clear physical meaning to the concept of ``small world,'' and also a precise quantitative analysis of both weighted and unweighted networks. We study neural networks and man-made communication and transportation systems and we show that the underlying general principle of their construction is in fact a small-world principle of high efficiency.}
}

@book{brockwellIntroductionTimeSeries2010,
    title = {Introduction to Time Series and Forecasting},
    author = {Brockwell, Peter J. and Davis, Richard A.},
    year = {2010},
    series = {Springer Texts in Statistics},
    edition = {Second edition, (corrected at 8th. printing 2010)},
    publisher = {Springer},
    address = {New York, NY},
    isbn = {978-0-387-95351-9},
    langid = {english}
}

@book{kirchgassnerIntroductionModernTime2013,
    title = {Introduction to {{Modern Time Series Analysis}}},
    author = {Kirchg{\"a}ssner, Gebhard and Wolters, J{\"u}rgen and Hassler, Uwe},
    year = {2013},
    series = {Springer {{Texts}} in {{Business}} and {{Economics}}},
    publisher = {Springer Berlin Heidelberg},
    address = {Berlin, Heidelberg},
    issn = {2192-4333, 2192-4341},
    doi = {10.1007/978-3-642-33436-8},
    urldate = {2025-07-22},
    copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
    isbn = {978-3-642-33435-1 978-3-642-33436-8},
    langid = {english}
}


@article{schreiberMeasuringInformationTransfer2000,
    title = {Measuring {{Information Transfer}}},
    author = {Schreiber, Thomas},
    year = {2000},
    month = jul,
    journal = {Physical Review Letters},
    volume = {85},
    number = {2},
    pages = {461--464},
    publisher = {American Physical Society},
    doi = {10.1103/PhysRevLett.85.461},
    urldate = {2025-04-22},
    abstract = {An information theoretic measure is derived that quantifies the statistical coherence between systems evolving in time. The standard time delayed mutual information fails to distinguish information that is actually exchanged from shared information due to common history and input signals. In our new approach, these influences are excluded by appropriate conditioning of transition probabilities. The resulting transfer entropy is able to distinguish effectively driving and responding elements and to detect asymmetry in the interaction of subsystems.}
}

@misc{buthInfomeasureComprehensivePython2025,
    title = {Infomeasure: {{A Comprehensive Python Package}} for {{Information Theory Measures}} and {{Estimators}}},
    shorttitle = {Infomeasure},
    author = {B{\"u}th, Carlson Moses and Acharya, Kishor and Zanin, Massimiliano},
    year = {2025},
    month = may,
    number = {arXiv:2505.14696},
    eprint = {2505.14696},
    primaryclass = {physics},
    publisher = {arXiv},
    doi = {10.48550/arXiv.2505.14696},
    urldate = {2025-07-22},
    abstract = {Information theory, i.e. the mathematical analysis of information and of its processing, has become a tenet of modern science; yet, its use in real-world studies is usually hindered by its computational complexity, the lack of coherent software frameworks, and, as a consequence, low reproducibility. We here introduce infomeasure, an open-source Python package designed to provide robust tools for calculating a wide variety of information-theoretic measures, including entropies, mutual information, transfer entropy and divergences. It is designed for both discrete and continuous variables; implements state-of-the-art estimation techniques; and allows the calculation of local measure values, \$p\$-values and \$t\$-scores. By unifying these approaches under one consistent framework, infomeasure aims to mitigate common pitfalls, ensure reproducibility, and simplify the practical implementation of information-theoretic analyses. In this contribution, we explore the motivation and features of infomeasure; its validation, using known analytical solutions; and exemplify its utility in a case study involving the analysis of human brain time series.},
    archiveprefix = {arXiv},
    keywords = {Computer Science - Information Theory,Mathematics - Information Theory,Physics - Computational Physics,Physics - Data Analysis Statistics and Probability,Physics - Physics and Society}
}

@article{olivaresEvaluatingMethodsDetrending2025,
    title = {Evaluating {{Methods}} for {{Detrending Time Series Using Ordinal Patterns}}, with an {{Application}} to {{Air Transport Delays}}},
    author = {Olivares, Felipe and {Mar{\'i}n-Rodr{\'i}guez}, F. Javier and Acharya, Kishor and Zanin, Massimiliano},
    year = {2025},
    month = mar,
    journal = {Entropy},
    volume = {27},
    number = {3},
    pages = {230},
    publisher = {Multidisciplinary Digital Publishing Institute},
    issn = {1099-4300},
    doi = {10.3390/e27030230},
    urldate = {2025-07-22},
    abstract = {Functional networks have become a standard tool for the analysis of complex systems, allowing the unveiling of their internal connectivity structure while only requiring the observation of the system's constituent dynamics. To obtain reliable results, one (often overlooked) prerequisite involves the stationarity of an analyzed time series, without which spurious functional connections may emerge. Here, we show how ordinal patterns and metrics derived from them can be used to assess the effectiveness of detrending methods. We apply this approach to data representing the evolution of delays in major European and US airports, and to synthetic versions of the same, obtaining operational conclusions about how these propagate in the two systems.},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    langid = {english},
    keywords = {causality,functional complex networks,ordinal patterns,stationarity,time series}
}

@article{zaninContinuousOrdinalPatterns2023,
    title = {Continuous Ordinal Patterns: {{Creating}} a Bridge between Ordinal Analysis and Deep Learning},
    shorttitle = {Continuous Ordinal Patterns},
    author = {Zanin, Massimiliano},
    year = {2023},
    month = mar,
    journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
    volume = {33},
    number = {3},
    pages = {033114},
    issn = {1054-1500},
    doi = {10.1063/5.0136492},
    urldate = {2025-07-22},
    abstract = {We introduce a generalization of the celebrated ordinal pattern approach for the analysis of time series, in which these are evaluated in terms of their distance to ordinal patterns defined in a continuous way. This allows us to naturally incorporate information about the local amplitude of the data and to optimize the ordinal pattern(s) to the problem under study. This last element represents a novel bridge between standard ordinal analysis and deep learning, allowing the achievement of results comparable to the latter in real-world classification problems while also retaining the conceptual simplicity, computational efficiency, and easy interpretability of the former. We test this through the use of synthetic time series, generated by standard chaotic maps and dynamical models, data sets representing brain activity in health and schizophrenia, and the dynamics of delays in the European air transport system. We further show how the continuous ordinal patterns can be used to assess other aspects of the dynamics, like time irreversibility.}
}
